{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ee296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub\n",
    "#!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c36b8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from simhash import SimHash\n",
    "from simhash_embed import SimHashEmbed\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca45bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = kagglehub.dataset_download(\"quora/question-pairs-dataset\")\n",
    "# print(\"Dataset gốc nằm ở:\", path)\n",
    "\n",
    "# target_dir = \"/home/hai/Projects/locality-sensitive-hashing/data/quora_question_pairs\"\n",
    "\n",
    "# os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# for item in os.listdir(path):\n",
    "#     s = os.path.join(path, item)\n",
    "#     d = os.path.join(target_dir, item)\n",
    "#     if os.path.isdir(s):\n",
    "#         shutil.copytree(s, d, dirs_exist_ok=True)\n",
    "#     else:\n",
    "#         shutil.copy2(s, d)\n",
    "\n",
    "# print(\"Dataset đã được copy vào:\", target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ad9a70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "659d70e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "def get_ngrams(text, n=N):\n",
    "    text = re.sub(r'\\s+', ' ', str(text)).strip()\n",
    "    tokens = []\n",
    "    for i in range(len(text) - n + 1):\n",
    "        tokens.append(text[i:i+n])      \n",
    "    return tokens\n",
    "\n",
    "def get_word_ngrams(text, n=2):\n",
    "    text = re.sub(r'\\s+', ' ', str(text)).strip().lower()\n",
    "    words = text.split()\n",
    "    tokens = []\n",
    "    for i in range(len(words)-n+1):\n",
    "        tokens.append(\" \".join(words[i:i+n]))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def preprocess(text, n=N):\n",
    "    remove_chars = string.punctuation + '@.'\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', remove_chars))\n",
    "    tokens = get_word_ngrams(text, n)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "511635f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>dist</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120567</th>\n",
       "      <td>120567</td>\n",
       "      <td>238932</td>\n",
       "      <td>238933</td>\n",
       "      <td>How does the Boggart work?</td>\n",
       "      <td>What would the boggart of a boggart be?</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;Simhash value=6012720904230808588364809449893...</td>\n",
       "      <td>&lt;Simhash value=8531778456708192513506923224210...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324466</th>\n",
       "      <td>324466</td>\n",
       "      <td>636476</td>\n",
       "      <td>636477</td>\n",
       "      <td>What is difference between project manager and...</td>\n",
       "      <td>What are the differences between project manag...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;Simhash value=2664038227359841099625818255919...</td>\n",
       "      <td>&lt;Simhash value=1193176379361672249056179228874...</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398558</th>\n",
       "      <td>398558</td>\n",
       "      <td>778728</td>\n",
       "      <td>778729</td>\n",
       "      <td>What hotel in Jabalpur would be safe for unmar...</td>\n",
       "      <td>What hotel in Allahabad would be safe for unma...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;Simhash value=1243671421109686292810893563980...</td>\n",
       "      <td>&lt;Simhash value=2259589700171580382467293539364...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339914</th>\n",
       "      <td>339914</td>\n",
       "      <td>666314</td>\n",
       "      <td>666315</td>\n",
       "      <td>What is stronger - Super Saiyan 4 or Super Sai...</td>\n",
       "      <td>How does Gohan turn into Super Saiyan 2?</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;Simhash value=2294950509384647050009680532638...</td>\n",
       "      <td>&lt;Simhash value=2926234899531282244417180975896...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185732</th>\n",
       "      <td>185732</td>\n",
       "      <td>366764</td>\n",
       "      <td>366765</td>\n",
       "      <td>How do I fill in Address Line 1 and Address Li...</td>\n",
       "      <td>How do I register desired web address?</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;Simhash value=2233649162609707169609166079834...</td>\n",
       "      <td>&lt;Simhash value=2565825475580597395369204787094...</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "120567  120567  238932  238933   \n",
       "324466  324466  636476  636477   \n",
       "398558  398558  778728  778729   \n",
       "339914  339914  666314  666315   \n",
       "185732  185732  366764  366765   \n",
       "\n",
       "                                                question1  \\\n",
       "120567                         How does the Boggart work?   \n",
       "324466  What is difference between project manager and...   \n",
       "398558  What hotel in Jabalpur would be safe for unmar...   \n",
       "339914  What is stronger - Super Saiyan 4 or Super Sai...   \n",
       "185732  How do I fill in Address Line 1 and Address Li...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "120567            What would the boggart of a boggart be?             0   \n",
       "324466  What are the differences between project manag...             0   \n",
       "398558  What hotel in Allahabad would be safe for unma...             0   \n",
       "339914           How does Gohan turn into Super Saiyan 2?             0   \n",
       "185732             How do I register desired web address?             0   \n",
       "\n",
       "                                                     sim1  \\\n",
       "120567  <Simhash value=6012720904230808588364809449893...   \n",
       "324466  <Simhash value=2664038227359841099625818255919...   \n",
       "398558  <Simhash value=1243671421109686292810893563980...   \n",
       "339914  <Simhash value=2294950509384647050009680532638...   \n",
       "185732  <Simhash value=2233649162609707169609166079834...   \n",
       "\n",
       "                                                     sim2  dist  pred  \n",
       "120567  <Simhash value=8531778456708192513506923224210...    57     0  \n",
       "324466  <Simhash value=1193176379361672249056179228874...    58     0  \n",
       "398558  <Simhash value=2259589700171580382467293539364...    15     0  \n",
       "339914  <Simhash value=2926234899531282244417180975896...    59     0  \n",
       "185732  <Simhash value=2565825475580597395369204787094...    58     0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/hai/Projects/locality-sensitive-hashing/data/quora_question_pairs/questions.csv\")\n",
    "df = df.sample(1000, random_state=42)\n",
    "df[\"sim1\"] = [SimHash(preprocess(q)) for q in df[\"question1\"]]\n",
    "df[\"sim2\"] = [SimHash(preprocess(q)) for q in df[\"question2\"]]\n",
    "df[\"dist\"] = [s1.distance(s2) for s1, s2 in zip(df[\"sim1\"], df[\"sim2\"])]\n",
    "K = 15\n",
    "df[\"pred\"] = (df[\"dist\"] < K). astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d6ac666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                question1  \\\n",
      "120567                         How does the Boggart work?   \n",
      "324466  What is difference between project manager and...   \n",
      "398558  What hotel in Jabalpur would be safe for unmar...   \n",
      "339914  What is stronger - Super Saiyan 4 or Super Sai...   \n",
      "185732  How do I fill in Address Line 1 and Address Li...   \n",
      "\n",
      "                                                question2  is_duplicate  dist  \\\n",
      "120567            What would the boggart of a boggart be?             0    33   \n",
      "324466  What are the differences between project manag...             0    27   \n",
      "398558  What hotel in Allahabad would be safe for unma...             0    21   \n",
      "339914           How does Gohan turn into Super Saiyan 2?             0    42   \n",
      "185732             How do I register desired web address?             0    45   \n",
      "\n",
      "        pred  \n",
      "120567     0  \n",
      "324466     0  \n",
      "398558     1  \n",
      "339914     0  \n",
      "185732     0  \n"
     ]
    }
   ],
   "source": [
    "df_eb = pd.read_csv(\"/home/hai/Projects/locality-sensitive-hashing/data/quora_question_pairs/questions.csv\")\n",
    "df_eb = df_eb.sample(1000, random_state=42)\n",
    "\n",
    "df_eb[\"sim1\"] = [SimHashEmbed(text=q, f=128, model=model) for q in df[\"question1\"]]\n",
    "df_eb[\"sim2\"] = [SimHashEmbed(text=q, f=128, model=model) for q in df[\"question2\"]]\n",
    "\n",
    "df_eb[\"dist\"] = [s1.distance(s2) for s1, s2 in zip(df_eb[\"sim1\"], df_eb[\"sim2\"])]\n",
    "\n",
    "K = 25\n",
    "df_eb[\"pred\"] = (df_eb[\"dist\"] < K).astype(int)\n",
    "\n",
    "print(df_eb[[\"question1\",\"question2\",\"is_duplicate\",\"dist\",\"pred\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e63e947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.3636\n",
      "Recall:0.0117\n",
      "F1-Score:0.0227\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(df[\"is_duplicate\"], df[\"pred\"])\n",
    "recall = recall_score(df[\"is_duplicate\"], df[\"pred\"])\n",
    "f1 = f1_score(df[\"is_duplicate\"], df[\"pred\"])\n",
    "print(f\"Precision:{precision:.4f}\")\n",
    "print(f\"Recall:{recall:.4f}\")\n",
    "print(f\"F1-Score:{f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eacf298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.6583\n",
      "Recall:0.6871\n",
      "F1-Score:0.6724\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(df_eb[\"is_duplicate\"], df_eb[\"pred\"])\n",
    "recall = recall_score(df_eb[\"is_duplicate\"], df_eb[\"pred\"])\n",
    "f1 = f1_score(df_eb[\"is_duplicate\"], df_eb[\"pred\"])\n",
    "print(f\"Precision:{precision:.4f}\")\n",
    "print(f\"Recall:{recall:.4f}\")\n",
    "print(f\"F1-Score:{f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
